{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main study\n",
    "\n",
    "In this file, I'll explore the data given by the OKCupid app, and will try to create ML models for analyzing and predicting data. \n",
    "\n",
    "The what's, how's and any more questions will come as I study the dataset. So read this file as a diary, where I code and ask myself questions. \n",
    "\n",
    "First, reading the data and getting columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 31 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   body_type    54650 non-null  object \n",
      " 2   diet         35551 non-null  object \n",
      " 3   drinks       56961 non-null  object \n",
      " 4   drugs        45866 non-null  object \n",
      " 5   education    53318 non-null  object \n",
      " 6   essay0       54458 non-null  object \n",
      " 7   essay1       52374 non-null  object \n",
      " 8   essay2       50308 non-null  object \n",
      " 9   essay3       48470 non-null  object \n",
      " 10  essay4       49409 non-null  object \n",
      " 11  essay5       49096 non-null  object \n",
      " 12  essay6       46175 non-null  object \n",
      " 13  essay7       47495 non-null  object \n",
      " 14  essay8       40721 non-null  object \n",
      " 15  essay9       47343 non-null  object \n",
      " 16  ethnicity    54266 non-null  object \n",
      " 17  height       59943 non-null  float64\n",
      " 18  income       59946 non-null  int64  \n",
      " 19  job          51748 non-null  object \n",
      " 20  last_online  59946 non-null  object \n",
      " 21  location     59946 non-null  object \n",
      " 22  offspring    24385 non-null  object \n",
      " 23  orientation  59946 non-null  object \n",
      " 24  pets         40025 non-null  object \n",
      " 25  religion     39720 non-null  object \n",
      " 26  sex          59946 non-null  object \n",
      " 27  sign         48890 non-null  object \n",
      " 28  smokes       54434 non-null  object \n",
      " 29  speaks       59896 non-null  object \n",
      " 30  status       59946 non-null  object \n",
      "dtypes: float64(1), int64(2), object(28)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "profiles = pd.read_csv('profiles.csv')\n",
    "\n",
    "profiles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>...</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>about me:&lt;br /&gt;\\n&lt;br /&gt;\\ni would love to think...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh.&lt;br /&gt;\\nranting about a go...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>...</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>i am a chef: this is what that means.&lt;br /&gt;\\n1...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>...</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn&amp;rsquo;t want kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at:&lt;br /&gt;\\nhttp://bag...</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age       body_type               diet    drinks      drugs  \\\n",
       "0   22  a little extra  strictly anything  socially      never   \n",
       "1   35         average       mostly other     often  sometimes   \n",
       "2   38            thin           anything  socially        NaN   \n",
       "3   23            thin         vegetarian  socially        NaN   \n",
       "4   29        athletic                NaN  socially      never   \n",
       "\n",
       "                           education  \\\n",
       "0      working on college/university   \n",
       "1              working on space camp   \n",
       "2     graduated from masters program   \n",
       "3      working on college/university   \n",
       "4  graduated from college/university   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  about me:<br />\\n<br />\\ni would love to think...   \n",
       "1  i am a chef: this is what that means.<br />\\n1...   \n",
       "2  i'm not ashamed of much, but writing public te...   \n",
       "3          i work in a library and go to school. . .   \n",
       "4  hey how's it going? currently vague on the pro...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "2  i make nerdy software for musicians, artists, ...   \n",
       "3          reading things written by old dead people   \n",
       "4                         work work work work + play   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh.<br />\\nranting about a go...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "2  improvising in different contexts. alternating...   \n",
       "3  playing synthesizers and organizing books acco...   \n",
       "4  creating imagery to look at:<br />\\nhttp://bag...   \n",
       "\n",
       "                                              essay3  ...  \\\n",
       "0  the way i look. i am a six foot half asian, ha...  ...   \n",
       "1                                                NaN  ...   \n",
       "2  my large jaw and large glasses are the physica...  ...   \n",
       "3                  socially awkward but i do my best  ...   \n",
       "4            i smile a lot and my inquisitive nature  ...   \n",
       "\n",
       "                          location  \\\n",
       "0  south san francisco, california   \n",
       "1              oakland, california   \n",
       "2        san francisco, california   \n",
       "3             berkeley, california   \n",
       "4        san francisco, california   \n",
       "\n",
       "                                      offspring orientation  \\\n",
       "0  doesn&rsquo;t have kids, but might want them    straight   \n",
       "1  doesn&rsquo;t have kids, but might want them    straight   \n",
       "2                                           NaN    straight   \n",
       "3                       doesn&rsquo;t want kids    straight   \n",
       "4                                           NaN    straight   \n",
       "\n",
       "                        pets                                  religion sex  \\\n",
       "0  likes dogs and likes cats     agnosticism and very serious about it   m   \n",
       "1  likes dogs and likes cats  agnosticism but not too serious about it   m   \n",
       "2                   has cats                                       NaN   m   \n",
       "3                 likes cats                                       NaN   m   \n",
       "4  likes dogs and likes cats                                       NaN   m   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "3                              pisces         no   \n",
       "4                            aquarius         no   \n",
       "\n",
       "                                              speaks     status  \n",
       "0                                            english     single  \n",
       "1  english (fluently), spanish (poorly), french (...     single  \n",
       "2                               english, french, c++  available  \n",
       "3                           english, german (poorly)     single  \n",
       "4                                            english     single  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                                                           22\n",
       "body_type                                         a little extra\n",
       "diet                                           strictly anything\n",
       "drinks                                                  socially\n",
       "drugs                                                      never\n",
       "education                          working on college/university\n",
       "essay0         about me:<br />\\n<br />\\ni would love to think...\n",
       "essay1         currently working as an international agent fo...\n",
       "essay2         making people laugh.<br />\\nranting about a go...\n",
       "essay3         the way i look. i am a six foot half asian, ha...\n",
       "essay4         books:<br />\\nabsurdistan, the republic, of mi...\n",
       "essay5         food.<br />\\nwater.<br />\\ncell phone.<br />\\n...\n",
       "essay6                               duality and humorous things\n",
       "essay7         trying to find someone to hang out with. i am ...\n",
       "essay8         i am new to california and looking for someone...\n",
       "essay9         you want to be swept off your feet!<br />\\nyou...\n",
       "ethnicity                                           asian, white\n",
       "height                                                      75.0\n",
       "income                                                        -1\n",
       "job                                               transportation\n",
       "last_online                                     2012-06-28-20-30\n",
       "location                         south san francisco, california\n",
       "offspring           doesn&rsquo;t have kids, but might want them\n",
       "orientation                                             straight\n",
       "pets                                   likes dogs and likes cats\n",
       "religion                   agnosticism and very serious about it\n",
       "sex                                                            m\n",
       "sign                                                      gemini\n",
       "smokes                                                 sometimes\n",
       "speaks                                                   english\n",
       "status                                                    single\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing data\n",
    "\n",
    "Fun stuff. First ideas are to label encode and to one-hot encode some stuff, but let's keep it open ended\n",
    "\n",
    "Let's check `body_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body_type\n",
       "average           14652\n",
       "fit               12711\n",
       "athletic          11819\n",
       "thin               4711\n",
       "curvy              3924\n",
       "a little extra     2629\n",
       "skinny             1777\n",
       "full figured       1009\n",
       "overweight          444\n",
       "jacked              421\n",
       "used up             355\n",
       "rather not say      198\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles['body_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body_type\n",
       "average           0.268106\n",
       "fit               0.232589\n",
       "athletic          0.216267\n",
       "thin              0.086203\n",
       "curvy             0.071802\n",
       "a little extra    0.048106\n",
       "skinny            0.032516\n",
       "full figured      0.018463\n",
       "overweight        0.008124\n",
       "jacked            0.007704\n",
       "used up           0.006496\n",
       "rather not say    0.003623\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles['body_type'].value_counts(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea was to label-encode this data, but there's no straight order (and it would have some social implications I guess), so one-hot enconding feels like the solution to input this data in the ML models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do notice there are 'rather not say' values and there are missing values, so we fill them with 'unknown'\n",
    "profiles['body_type'] = profiles['body_type'].fillna(value='unknown')\n",
    "\n",
    "profiles = pd.get_dummies(profiles, prefix='body_type', columns=['body_type'], dtype=int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for `diet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diet\n",
       "mostly anything        16585\n",
       "anything                6183\n",
       "strictly anything       5113\n",
       "mostly vegetarian       3444\n",
       "mostly other            1007\n",
       "strictly vegetarian      875\n",
       "vegetarian               667\n",
       "strictly other           452\n",
       "mostly vegan             338\n",
       "other                    331\n",
       "strictly vegan           228\n",
       "vegan                    136\n",
       "mostly kosher             86\n",
       "mostly halal              48\n",
       "strictly halal            18\n",
       "strictly kosher           18\n",
       "halal                     11\n",
       "kosher                    11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles['diet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diet\n",
       "mostly anything        0.466513\n",
       "anything               0.173919\n",
       "strictly anything      0.143822\n",
       "mostly vegetarian      0.096875\n",
       "mostly other           0.028326\n",
       "strictly vegetarian    0.024613\n",
       "vegetarian             0.018762\n",
       "strictly other         0.012714\n",
       "mostly vegan           0.009507\n",
       "other                  0.009311\n",
       "strictly vegan         0.006413\n",
       "vegan                  0.003825\n",
       "mostly kosher          0.002419\n",
       "mostly halal           0.001350\n",
       "strictly halal         0.000506\n",
       "strictly kosher        0.000506\n",
       "halal                  0.000309\n",
       "kosher                 0.000309\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles['diet'].value_counts(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here there is not even an attempt at labeling. But also, getting dummies will create 17 new columns.\n",
    "\n",
    "But, there are values that repeat themselves. Like some peopel will be 'mostly vegan' and some other people are 'stricly vegan'. So the idea is to make a have informations like vegan = true and strictness = mostly (or something like this).\n",
    "\n",
    "So I'll one-hot encode the type of diet (vegan, anything, kosher ...).\n",
    "\n",
    "But the 'strictness' feels weird. In one sense, feels logical for no prefix to be labeled 0, mostly is 1, and stricly is 2. On the other sense, imagine one person answered 'vegan', other 'mostly vegan', and the last, 'stricly vegan'. Then, the weaker intention on being vegan falls on the 'mostly' and the higher one, 'stricly', putting the 'no-prefix' in the middle. In that sense, the base-line would be 1 (no prefix), 0's are for 'mostly's and 'stricly' is gonna be 2 (not changed)\n",
    "\n",
    "There's also a 'why' would someone answer 'anything' and 'stricly anything' which I can't quite grasp, so I'll just stick with the numbers. Also, we'll set baselines of strictness @ 0 for convenience, so mostly is a -1\n",
    "\n",
    "**Conclusion**: We'll one-hot encode diet_type and label strictness as such:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'stricly': 1,\n",
    "    'mostly': -1,\n",
    "    # anything else is a 0 (middle value)\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psena\\AppData\\Local\\Temp\\ipykernel_2492\\2375089356.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  profiles['diet'].fillna('unknown', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       59946 non-null  int64  \n",
      " 1   drinks                    56961 non-null  object \n",
      " 2   drugs                     45866 non-null  object \n",
      " 3   education                 53318 non-null  object \n",
      " 4   essay0                    54458 non-null  object \n",
      " 5   essay1                    52374 non-null  object \n",
      " 6   essay2                    50308 non-null  object \n",
      " 7   essay3                    48470 non-null  object \n",
      " 8   essay4                    49409 non-null  object \n",
      " 9   essay5                    49096 non-null  object \n",
      " 10  essay6                    46175 non-null  object \n",
      " 11  essay7                    47495 non-null  object \n",
      " 12  essay8                    40721 non-null  object \n",
      " 13  essay9                    47343 non-null  object \n",
      " 14  ethnicity                 54266 non-null  object \n",
      " 15  height                    59943 non-null  float64\n",
      " 16  income                    59946 non-null  int64  \n",
      " 17  job                       51748 non-null  object \n",
      " 18  last_online               59946 non-null  object \n",
      " 19  location                  59946 non-null  object \n",
      " 20  offspring                 24385 non-null  object \n",
      " 21  orientation               59946 non-null  object \n",
      " 22  pets                      40025 non-null  object \n",
      " 23  religion                  39720 non-null  object \n",
      " 24  sex                       59946 non-null  object \n",
      " 25  sign                      48890 non-null  object \n",
      " 26  smokes                    54434 non-null  object \n",
      " 27  speaks                    59896 non-null  object \n",
      " 28  status                    59946 non-null  object \n",
      " 29  body_type_a little extra  59946 non-null  int64  \n",
      " 30  body_type_athletic        59946 non-null  int64  \n",
      " 31  body_type_average         59946 non-null  int64  \n",
      " 32  body_type_curvy           59946 non-null  int64  \n",
      " 33  body_type_fit             59946 non-null  int64  \n",
      " 34  body_type_full figured    59946 non-null  int64  \n",
      " 35  body_type_jacked          59946 non-null  int64  \n",
      " 36  body_type_overweight      59946 non-null  int64  \n",
      " 37  body_type_rather not say  59946 non-null  int64  \n",
      " 38  body_type_skinny          59946 non-null  int64  \n",
      " 39  body_type_thin            59946 non-null  int64  \n",
      " 40  body_type_unknown         59946 non-null  int64  \n",
      " 41  body_type_used up         59946 non-null  int64  \n",
      " 42  diet_type_anything        59946 non-null  int64  \n",
      " 43  diet_type_halal           59946 non-null  int64  \n",
      " 44  diet_type_kosher          59946 non-null  int64  \n",
      " 45  diet_type_other           59946 non-null  int64  \n",
      " 46  diet_type_unknown         59946 non-null  int64  \n",
      " 47  diet_type_vegan           59946 non-null  int64  \n",
      " 48  diet_type_vegetarian      59946 non-null  int64  \n",
      " 49  diet_strictness           59946 non-null  int64  \n",
      "dtypes: float64(1), int64(23), object(26)\n",
      "memory usage: 22.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# fill NaN with unknown \n",
    "profiles['diet'].fillna('unknown', inplace=True)\n",
    "\n",
    "# creates and 1-hto-encodes diet types\n",
    "profiles['diet_type'] = profiles['diet'].str.replace(r'^(strictly |mostly )', '', regex=True)\n",
    "profiles = pd.get_dummies(profiles, columns=['diet_type'], dtype=int)\n",
    "\n",
    "# middleware: for labelling\n",
    "def get_strictness(x):\n",
    "    if 'stricly' in x: \n",
    "        return 1\n",
    "    elif 'mostly' in x: \n",
    "        return -1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "# labels\n",
    "profiles['diet_strictness'] = profiles['diet'].apply(get_strictness)\n",
    "\n",
    "profiles.drop(columns=['diet'], inplace=True, axis=1)\n",
    "\n",
    "profiles.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now for drinking!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drinks\n",
      "socially       41780\n",
      "rarely          5957\n",
      "often           5164\n",
      "not at all      3267\n",
      "very often       471\n",
      "desperately      322\n",
      "Name: count, dtype: int64\n",
      "drinks\n",
      "socially       0.733484\n",
      "rarely         0.104580\n",
      "often          0.090659\n",
      "not at all     0.057355\n",
      "very often     0.008269\n",
      "desperately    0.005653\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(profiles['drinks'].value_counts())\n",
    "print(profiles['drinks'].value_counts(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there can be a order to it, so labeling from 0 to 5 (6 values) might be the way to go\n",
    "- 0 -> not at all\n",
    "- 1 -> rarely\n",
    "- 2 -> socially\n",
    "- 3 -> often\n",
    "- 4 -> very often\n",
    "- 5 -> desperately\n",
    "\n",
    "BUT missings values are a pain. Socially IS the main value by a long shot, so instead of filling NaN with the string 'unknwon', I'll opt to make NaN become 'socially'.\n",
    "\n",
    "There's obviously pro's and con's on doing this, but since the answers can be with an implied order, keeping said order feels like the right choice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drinks\n",
      "2    44765\n",
      "1     5957\n",
      "3     5164\n",
      "0     3267\n",
      "4      471\n",
      "5      322\n",
      "Name: count, dtype: int64\n",
      "drinks\n",
      "2    0.746755\n",
      "1    0.099373\n",
      "3    0.086144\n",
      "0    0.054499\n",
      "4    0.007857\n",
      "5    0.005372\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "profiles['drinks'] = profiles['drinks'].fillna('socially')\n",
    "\n",
    "profiles['drinks'] = profiles['drinks'].map({\n",
    "    'not at all': 0,\n",
    "    'rarely': 1,\n",
    "    'socially': 2,\n",
    "    'often': 3,\n",
    "    'very often': 4,\n",
    "    'desperately': 5,\n",
    "})\n",
    "\n",
    "print(profiles['drinks'].value_counts())\n",
    "print(profiles['drinks'].value_counts(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       59946 non-null  int64  \n",
      " 1   drinks                    59946 non-null  int64  \n",
      " 2   drugs                     45866 non-null  object \n",
      " 3   education                 53318 non-null  object \n",
      " 4   essay0                    54458 non-null  object \n",
      " 5   essay1                    52374 non-null  object \n",
      " 6   essay2                    50308 non-null  object \n",
      " 7   essay3                    48470 non-null  object \n",
      " 8   essay4                    49409 non-null  object \n",
      " 9   essay5                    49096 non-null  object \n",
      " 10  essay6                    46175 non-null  object \n",
      " 11  essay7                    47495 non-null  object \n",
      " 12  essay8                    40721 non-null  object \n",
      " 13  essay9                    47343 non-null  object \n",
      " 14  ethnicity                 54266 non-null  object \n",
      " 15  height                    59943 non-null  float64\n",
      " 16  income                    59946 non-null  int64  \n",
      " 17  job                       51748 non-null  object \n",
      " 18  last_online               59946 non-null  object \n",
      " 19  location                  59946 non-null  object \n",
      " 20  offspring                 24385 non-null  object \n",
      " 21  orientation               59946 non-null  object \n",
      " 22  pets                      40025 non-null  object \n",
      " 23  religion                  39720 non-null  object \n",
      " 24  sex                       59946 non-null  object \n",
      " 25  sign                      48890 non-null  object \n",
      " 26  smokes                    54434 non-null  object \n",
      " 27  speaks                    59896 non-null  object \n",
      " 28  status                    59946 non-null  object \n",
      " 29  body_type_a little extra  59946 non-null  int64  \n",
      " 30  body_type_athletic        59946 non-null  int64  \n",
      " 31  body_type_average         59946 non-null  int64  \n",
      " 32  body_type_curvy           59946 non-null  int64  \n",
      " 33  body_type_fit             59946 non-null  int64  \n",
      " 34  body_type_full figured    59946 non-null  int64  \n",
      " 35  body_type_jacked          59946 non-null  int64  \n",
      " 36  body_type_overweight      59946 non-null  int64  \n",
      " 37  body_type_rather not say  59946 non-null  int64  \n",
      " 38  body_type_skinny          59946 non-null  int64  \n",
      " 39  body_type_thin            59946 non-null  int64  \n",
      " 40  body_type_unknown         59946 non-null  int64  \n",
      " 41  body_type_used up         59946 non-null  int64  \n",
      " 42  diet_type_anything        59946 non-null  int64  \n",
      " 43  diet_type_halal           59946 non-null  int64  \n",
      " 44  diet_type_kosher          59946 non-null  int64  \n",
      " 45  diet_type_other           59946 non-null  int64  \n",
      " 46  diet_type_unknown         59946 non-null  int64  \n",
      " 47  diet_type_vegan           59946 non-null  int64  \n",
      " 48  diet_type_vegetarian      59946 non-null  int64  \n",
      " 49  diet_strictness           59946 non-null  int64  \n",
      "dtypes: float64(1), int64(24), object(25)\n",
      "memory usage: 22.9+ MB\n"
     ]
    }
   ],
   "source": [
    "profiles.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drugs\n",
      "never        37724\n",
      "sometimes     7732\n",
      "often          410\n",
      "Name: count, dtype: int64\n",
      "drugs\n",
      "never        0.822483\n",
      "sometimes    0.168578\n",
      "often        0.008939\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(profiles['drugs'].value_counts(0))\n",
    "print(profiles['drugs'].value_counts(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For exploratory reasons, I'll put label all missing values to the mode(never). It can be a controversy choice, since not answering the drug questions can also be seeing as a stigma of some sorts, but I'll just keep this in mind when analysing the model. ALSO there's like more than 10k missing values in this column, so there's that\n",
    "\n",
    "I choose to do this because there's a clear labeling order, and I'd rather keep it :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['drugs'] = profiles['drugs'].fillna('never')\n",
    "\n",
    "profiles['drugs'] = profiles['drugs'].map({\n",
    "    'never': 0,\n",
    "    'sometimes': 1,\n",
    "    'often': 2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drugs\n",
      "0    51804\n",
      "1     7732\n",
      "2      410\n",
      "Name: count, dtype: int64\n",
      "drugs\n",
      "0    0.864178\n",
      "1    0.128983\n",
      "2    0.006839\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(profiles['drugs'].value_counts(0))\n",
    "print(profiles['drugs'].value_counts(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, let's keep in mind this should affect our model in the end!\n",
    "\n",
    "## Education!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education\n",
      "graduated from college/university    23959\n",
      "graduated from masters program        8961\n",
      "working on college/university         5712\n",
      "working on masters program            1683\n",
      "graduated from two-year college       1531\n",
      "graduated from high school            1428\n",
      "graduated from ph.d program           1272\n",
      "graduated from law school             1122\n",
      "working on two-year college           1074\n",
      "dropped out of college/university      995\n",
      "working on ph.d program                983\n",
      "college/university                     801\n",
      "graduated from space camp              657\n",
      "dropped out of space camp              523\n",
      "graduated from med school              446\n",
      "working on space camp                  445\n",
      "working on law school                  269\n",
      "two-year college                       222\n",
      "working on med school                  212\n",
      "dropped out of two-year college        191\n",
      "dropped out of masters program         140\n",
      "masters program                        136\n",
      "dropped out of ph.d program            127\n",
      "dropped out of high school             102\n",
      "high school                             96\n",
      "working on high school                  87\n",
      "space camp                              58\n",
      "ph.d program                            26\n",
      "law school                              19\n",
      "dropped out of law school               18\n",
      "dropped out of med school               12\n",
      "med school                              11\n",
      "Name: count, dtype: int64\n",
      "education\n",
      "graduated from college/university    0.449360\n",
      "graduated from masters program       0.168067\n",
      "working on college/university        0.107131\n",
      "working on masters program           0.031565\n",
      "graduated from two-year college      0.028715\n",
      "graduated from high school           0.026783\n",
      "graduated from ph.d program          0.023857\n",
      "graduated from law school            0.021044\n",
      "working on two-year college          0.020143\n",
      "dropped out of college/university    0.018662\n",
      "working on ph.d program              0.018437\n",
      "college/university                   0.015023\n",
      "graduated from space camp            0.012322\n",
      "dropped out of space camp            0.009809\n",
      "graduated from med school            0.008365\n",
      "working on space camp                0.008346\n",
      "working on law school                0.005045\n",
      "two-year college                     0.004164\n",
      "working on med school                0.003976\n",
      "dropped out of two-year college      0.003582\n",
      "dropped out of masters program       0.002626\n",
      "masters program                      0.002551\n",
      "dropped out of ph.d program          0.002382\n",
      "dropped out of high school           0.001913\n",
      "high school                          0.001801\n",
      "working on high school               0.001632\n",
      "space camp                           0.001088\n",
      "ph.d program                         0.000488\n",
      "law school                           0.000356\n",
      "dropped out of law school            0.000338\n",
      "dropped out of med school            0.000225\n",
      "med school                           0.000206\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(profiles['education'].value_counts(0))\n",
    "print(profiles['education'].value_counts(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is cool, but will be the same idea for the diets. We'll have the education status, where options are graduated, working, dropped, and education level, where it can be college/university, masters program, two-year college, high school. ph.d program, law school, space camp (wow), med school.\n",
    "\n",
    "Here, NaN are to be 'unkown', since it's literally that and there will be no attempt to order anything.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 63 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   age                                 59946 non-null  int64  \n",
      " 1   drinks                              59946 non-null  int64  \n",
      " 2   drugs                               59946 non-null  int64  \n",
      " 3   essay0                              54458 non-null  object \n",
      " 4   essay1                              52374 non-null  object \n",
      " 5   essay2                              50308 non-null  object \n",
      " 6   essay3                              48470 non-null  object \n",
      " 7   essay4                              49409 non-null  object \n",
      " 8   essay5                              49096 non-null  object \n",
      " 9   essay6                              46175 non-null  object \n",
      " 10  essay7                              47495 non-null  object \n",
      " 11  essay8                              40721 non-null  object \n",
      " 12  essay9                              47343 non-null  object \n",
      " 13  ethnicity                           54266 non-null  object \n",
      " 14  height                              59943 non-null  float64\n",
      " 15  income                              59946 non-null  int64  \n",
      " 16  job                                 51748 non-null  object \n",
      " 17  last_online                         59946 non-null  object \n",
      " 18  location                            59946 non-null  object \n",
      " 19  offspring                           24385 non-null  object \n",
      " 20  orientation                         59946 non-null  object \n",
      " 21  pets                                40025 non-null  object \n",
      " 22  religion                            39720 non-null  object \n",
      " 23  sex                                 59946 non-null  object \n",
      " 24  sign                                48890 non-null  object \n",
      " 25  smokes                              54434 non-null  object \n",
      " 26  speaks                              59896 non-null  object \n",
      " 27  status                              59946 non-null  object \n",
      " 28  body_type_a little extra            59946 non-null  int64  \n",
      " 29  body_type_athletic                  59946 non-null  int64  \n",
      " 30  body_type_average                   59946 non-null  int64  \n",
      " 31  body_type_curvy                     59946 non-null  int64  \n",
      " 32  body_type_fit                       59946 non-null  int64  \n",
      " 33  body_type_full figured              59946 non-null  int64  \n",
      " 34  body_type_jacked                    59946 non-null  int64  \n",
      " 35  body_type_overweight                59946 non-null  int64  \n",
      " 36  body_type_rather not say            59946 non-null  int64  \n",
      " 37  body_type_skinny                    59946 non-null  int64  \n",
      " 38  body_type_thin                      59946 non-null  int64  \n",
      " 39  body_type_unknown                   59946 non-null  int64  \n",
      " 40  body_type_used up                   59946 non-null  int64  \n",
      " 41  diet_type_anything                  59946 non-null  int64  \n",
      " 42  diet_type_halal                     59946 non-null  int64  \n",
      " 43  diet_type_kosher                    59946 non-null  int64  \n",
      " 44  diet_type_other                     59946 non-null  int64  \n",
      " 45  diet_type_unknown                   59946 non-null  int64  \n",
      " 46  diet_type_vegan                     59946 non-null  int64  \n",
      " 47  diet_type_vegetarian                59946 non-null  int64  \n",
      " 48  diet_strictness                     59946 non-null  int64  \n",
      " 49  education_status_dropped_out        59946 non-null  int64  \n",
      " 50  education_status_graduated          59946 non-null  int64  \n",
      " 51  education_status_unknown            59946 non-null  int64  \n",
      " 52  education_status_unspecified        59946 non-null  int64  \n",
      " 53  education_status_working_on         59946 non-null  int64  \n",
      " 54  education_level_college/university  59946 non-null  int64  \n",
      " 55  education_level_high school         59946 non-null  int64  \n",
      " 56  education_level_law school          59946 non-null  int64  \n",
      " 57  education_level_masters program     59946 non-null  int64  \n",
      " 58  education_level_med school          59946 non-null  int64  \n",
      " 59  education_level_ph.d program        59946 non-null  int64  \n",
      " 60  education_level_space camp          59946 non-null  int64  \n",
      " 61  education_level_two-year college    59946 non-null  int64  \n",
      " 62  education_level_unknown             59946 non-null  int64  \n",
      "dtypes: float64(1), int64(39), object(23)\n",
      "memory usage: 28.8+ MB\n"
     ]
    }
   ],
   "source": [
    "profiles['education'] = profiles['education'].fillna('unknown')\n",
    "# get columns with only education_level\n",
    "profiles['education_level'] = profiles['education'].replace(['graduated from ', 'working on ', 'dropped out of '], '', regex=True)\n",
    "\n",
    "# get columns with education status\n",
    "# middleware \n",
    "def get_edu_status(x):\n",
    "    if 'graduated from ' in x: \n",
    "        return 'graduated'\n",
    "    elif 'working on ' in x:\n",
    "        return 'working_on'\n",
    "    elif 'dropped out of ' in x: \n",
    "        return 'dropped_out'\n",
    "    elif 'unknown' in x:\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        return 'unspecified'\n",
    "\n",
    "profiles['education_status'] = profiles['education'].apply(get_edu_status)\n",
    "profiles = pd.get_dummies(profiles, columns=['education_status', 'education_level'], dtype=int)\n",
    "\n",
    "profiles = profiles.drop('education', axis=1)\n",
    "\n",
    "\n",
    "profiles.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ethinicity!\n",
    "let's have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54266\n",
      "ethnicity\n",
      "white                                                                                                      0.605001\n",
      "asian                                                                                                      0.113036\n",
      "hispanic / latin                                                                                           0.052022\n",
      "black                                                                                                      0.037003\n",
      "other                                                                                                      0.031438\n",
      "hispanic / latin, white                                                                                    0.023974\n",
      "indian                                                                                                     0.019847\n",
      "asian, white                                                                                               0.014945\n",
      "white, other                                                                                               0.011812\n",
      "pacific islander                                                                                           0.007961\n",
      "asian, pacific islander                                                                                    0.007279\n",
      "native american, white                                                                                     0.006229\n",
      "middle eastern                                                                                             0.006063\n",
      "middle eastern, white                                                                                      0.005528\n",
      "black, white                                                                                               0.005491\n",
      "pacific islander, white                                                                                    0.002875\n",
      "hispanic / latin, other                                                                                    0.002543\n",
      "black, other                                                                                               0.002451\n",
      "black, hispanic / latin                                                                                    0.002193\n",
      "hispanic / latin, white, other                                                                             0.002156\n",
      "black, native american, white                                                                              0.002027\n",
      "black, native american                                                                                     0.001843\n",
      "asian, other                                                                                               0.001751\n",
      "asian, hispanic / latin                                                                                    0.001622\n",
      "native american, hispanic / latin, white                                                                   0.001603\n",
      "native american, hispanic / latin                                                                          0.001345\n",
      "asian, white, other                                                                                        0.001272\n",
      "native american                                                                                            0.001235\n",
      "asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other    0.001216\n",
      "asian, black                                                                                               0.001087\n",
      "pacific islander, hispanic / latin                                                                         0.001050\n",
      "asian, pacific islander, white                                                                             0.001014\n",
      "native american, white, other                                                                              0.000995\n",
      "asian, indian                                                                                              0.000958\n",
      "black, white, other                                                                                        0.000903\n",
      "indian, white                                                                                              0.000848\n",
      "asian, hispanic / latin, white                                                                             0.000774\n",
      "middle eastern, white, other                                                                               0.000737\n",
      "middle eastern, hispanic / latin                                                                           0.000719\n",
      "asian, pacific islander, other                                                                             0.000700\n",
      "black, hispanic / latin, white                                                                             0.000663\n",
      "native american, hispanic / latin, white, other                                                            0.000608\n",
      "pacific islander, hispanic / latin, white                                                                  0.000553\n",
      "indian, other                                                                                              0.000553\n",
      "black, native american, white, other                                                                       0.000534\n",
      "black, native american, other                                                                              0.000498\n",
      "black, native american, hispanic / latin, white                                                            0.000479\n",
      "middle eastern, other                                                                                      0.000424\n",
      "black, native american, hispanic / latin                                                                   0.000350\n",
      "pacific islander, white, other                                                                             0.000332\n",
      "asian, native american, white                                                                              0.000332\n",
      "black, indian                                                                                              0.000313\n",
      "native american, other                                                                                     0.000295\n",
      "asian, black, white                                                                                        0.000276\n",
      "black, pacific islander                                                                                    0.000276\n",
      "pacific islander, other                                                                                    0.000258\n",
      "indian, white, other                                                                                       0.000258\n",
      "black, hispanic / latin, other                                                                             0.000240\n",
      "asian, pacific islander, hispanic / latin                                                                  0.000240\n",
      "native american, hispanic / latin, other                                                                   0.000240\n",
      "middle eastern, hispanic / latin, white                                                                    0.000221\n",
      "indian, pacific islander                                                                                   0.000221\n",
      "asian, middle eastern                                                                                      0.000221\n",
      "asian, pacific islander, hispanic / latin, white                                                           0.000203\n",
      "middle eastern, indian                                                                                     0.000203\n",
      "asian, pacific islander, white, other                                                                      0.000184\n",
      "black, native american, hispanic / latin, white, other                                                     0.000184\n",
      "asian, black, native american                                                                              0.000166\n",
      "asian, hispanic / latin, white, other                                                                      0.000166\n",
      "asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white           0.000166\n",
      "asian, middle eastern, white                                                                               0.000166\n",
      "asian, hispanic / latin, other                                                                             0.000166\n",
      "asian, black, other                                                                                        0.000166\n",
      "middle eastern, native american, white                                                                     0.000147\n",
      "indian, hispanic / latin                                                                                   0.000147\n",
      "asian, black, native american, white                                                                       0.000147\n",
      "asian, native american, hispanic / latin, white                                                            0.000129\n",
      "native american, pacific islander, white                                                                   0.000129\n",
      "asian, indian, pacific islander                                                                            0.000111\n",
      "black, indian, white                                                                                       0.000111\n",
      "middle eastern, black                                                                                      0.000111\n",
      "asian, black, pacific islander                                                                             0.000111\n",
      "asian, middle eastern, white, other                                                                        0.000111\n",
      "native american, pacific islander, hispanic / latin                                                        0.000092\n",
      "asian, middle eastern, indian                                                                              0.000092\n",
      "native american, pacific islander, hispanic / latin, white                                                 0.000092\n",
      "pacific islander, hispanic / latin, white, other                                                           0.000092\n",
      "asian, native american, white, other                                                                       0.000092\n",
      "black, native american, hispanic / latin, other                                                            0.000092\n",
      "asian, native american, hispanic / latin                                                                   0.000092\n",
      "black, hispanic / latin, white, other                                                                      0.000092\n",
      "asian, pacific islander, hispanic / latin, white, other                                                    0.000092\n",
      "asian, indian, other                                                                                       0.000092\n",
      "asian, indian, white                                                                                       0.000092\n",
      "black, pacific islander, hispanic / latin                                                                  0.000092\n",
      "pacific islander, hispanic / latin, other                                                                  0.000092\n",
      "black, pacific islander, white                                                                             0.000074\n",
      "asian, native american, pacific islander, hispanic / latin, white                                          0.000074\n",
      "asian, native american, hispanic / latin, white, other                                                     0.000074\n",
      "middle eastern, indian, other                                                                              0.000074\n",
      "middle eastern, hispanic / latin, other                                                                    0.000074\n",
      "black, pacific islander, other                                                                             0.000074\n",
      "asian, black, pacific islander, hispanic / latin                                                           0.000074\n",
      "indian, hispanic / latin, other                                                                            0.000074\n",
      "black, indian, white, other                                                                                0.000074\n",
      "asian, native american                                                                                     0.000055\n",
      "middle eastern, native american, hispanic / latin                                                          0.000055\n",
      "black, indian, hispanic / latin                                                                            0.000055\n",
      "asian, indian, pacific islander, other                                                                     0.000055\n",
      "middle eastern, pacific islander, other                                                                    0.000055\n",
      "black, native american, indian, other                                                                      0.000055\n",
      "native american, pacific islander, hispanic / latin, white, other                                          0.000055\n",
      "asian, black, native american, pacific islander, white                                                     0.000055\n",
      "asian, middle eastern, indian, other                                                                       0.000055\n",
      "black, indian, other                                                                                       0.000055\n",
      "asian, middle eastern, native american, indian, pacific islander, hispanic / latin, white                  0.000037\n",
      "asian, black, hispanic / latin                                                                             0.000037\n",
      "native american, pacific islander                                                                          0.000037\n",
      "asian, middle eastern, black                                                                               0.000037\n",
      "asian, black, native american, hispanic / latin, white                                                     0.000037\n",
      "asian, middle eastern, black, pacific islander, hispanic / latin, white                                    0.000037\n",
      "asian, black, native american, white, other                                                                0.000037\n",
      "black, indian, hispanic / latin, white                                                                     0.000037\n",
      "asian, native american, pacific islander, white, other                                                     0.000037\n",
      "asian, indian, hispanic / latin                                                                            0.000037\n",
      "asian, indian, white, other                                                                                0.000037\n",
      "middle eastern, hispanic / latin, white, other                                                             0.000037\n",
      "asian, black, hispanic / latin, other                                                                      0.000037\n",
      "native american, pacific islander, white, other                                                            0.000037\n",
      "asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, other           0.000037\n",
      "middle eastern, black, native american, white                                                              0.000037\n",
      "indian, hispanic / latin, white                                                                            0.000037\n",
      "asian, native american, pacific islander, white                                                            0.000037\n",
      "asian, native american, other                                                                              0.000037\n",
      "indian, hispanic / latin, white, other                                                                     0.000037\n",
      "middle eastern, native american, hispanic / latin, white                                                   0.000037\n",
      "asian, black, pacific islander, white                                                                      0.000037\n",
      "asian, pacific islander, hispanic / latin, other                                                           0.000037\n",
      "black, native american, pacific islander, white                                                            0.000037\n",
      "asian, black, native american, pacific islander                                                            0.000037\n",
      "middle eastern, indian, white, other                                                                       0.000037\n",
      "black, native american, pacific islander, hispanic / latin, white                                          0.000037\n",
      "asian, middle eastern, black, indian, pacific islander, hispanic / latin, white                            0.000037\n",
      "asian, middle eastern, hispanic / latin, white                                                             0.000037\n",
      "black, native american, pacific islander, hispanic / latin, white, other                                   0.000037\n",
      "asian, middle eastern, black, native american, pacific islander, hispanic / latin, white, other            0.000037\n",
      "middle eastern, native american, hispanic / latin, white, other                                            0.000037\n",
      "native american, indian                                                                                    0.000037\n",
      "middle eastern, black, white                                                                               0.000037\n",
      "middle eastern, black, native american, indian, white, other                                               0.000037\n",
      "black, native american, pacific islander                                                                   0.000037\n",
      "asian, black, native american, other                                                                       0.000037\n",
      "asian, black, native american, hispanic / latin                                                            0.000037\n",
      "asian, black, hispanic / latin, white                                                                      0.000037\n",
      "asian, native american, pacific islander                                                                   0.000037\n",
      "black, native american, indian, white, other                                                               0.000037\n",
      "asian, black, native american, pacific islander, other                                                     0.000018\n",
      "asian, middle eastern, black, native american, indian, pacific islander, white                             0.000018\n",
      "asian, indian, hispanic / latin, white                                                                     0.000018\n",
      "asian, black, native american, indian, hispanic / latin, white, other                                      0.000018\n",
      "asian, black, indian, hispanic / latin, other                                                              0.000018\n",
      "asian, indian, pacific islander, hispanic / latin, white, other                                            0.000018\n",
      "asian, middle eastern, black, native american, hispanic / latin, white                                     0.000018\n",
      "asian, middle eastern, other                                                                               0.000018\n",
      "middle eastern, pacific islander                                                                           0.000018\n",
      "middle eastern, indian, white                                                                              0.000018\n",
      "middle eastern, black, native american, indian, hispanic / latin, white                                    0.000018\n",
      "middle eastern, black, native american, white, other                                                       0.000018\n",
      "black, native american, pacific islander, other                                                            0.000018\n",
      "middle eastern, black, pacific islander, white                                                             0.000018\n",
      "middle eastern, black, indian, pacific islander, hispanic / latin, white                                   0.000018\n",
      "black, native american, indian, white                                                                      0.000018\n",
      "asian, middle eastern, indian, hispanic / latin, white, other                                              0.000018\n",
      "asian, middle eastern, native american, hispanic / latin, white                                            0.000018\n",
      "middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other           0.000018\n",
      "asian, black, native american, indian                                                                      0.000018\n",
      "middle eastern, black, native american, indian, pacific islander, hispanic / latin, white                  0.000018\n",
      "middle eastern, black, hispanic / latin                                                                    0.000018\n",
      "black, native american, pacific islander, white, other                                                     0.000018\n",
      "black, native american, indian, hispanic / latin, white, other                                             0.000018\n",
      "asian, indian, hispanic / latin, other                                                                     0.000018\n",
      "asian, black, hispanic / latin, white, other                                                               0.000018\n",
      "asian, native american, pacific islander, hispanic / latin, white, other                                   0.000018\n",
      "middle eastern, native american                                                                            0.000018\n",
      "middle eastern, black, native american, hispanic / latin, white                                            0.000018\n",
      "black, native american, indian, pacific islander, hispanic / latin                                         0.000018\n",
      "asian, middle eastern, black, white, other                                                                 0.000018\n",
      "asian, middle eastern, black, pacific islander                                                             0.000018\n",
      "asian, black, white, other                                                                                 0.000018\n",
      "asian, middle eastern, native american, pacific islander, hispanic / latin, white, other                   0.000018\n",
      "native american, indian, pacific islander, hispanic / latin                                                0.000018\n",
      "asian, black, native american, indian, pacific islander, white                                             0.000018\n",
      "middle eastern, pacific islander, hispanic / latin                                                         0.000018\n",
      "asian, black, native american, pacific islander, white, other                                              0.000018\n",
      "asian, middle eastern, hispanic / latin                                                                    0.000018\n",
      "asian, black, pacific islander, other                                                                      0.000018\n",
      "asian, native american, indian, pacific islander, hispanic / latin, white                                  0.000018\n",
      "middle eastern, native american, white, other                                                              0.000018\n",
      "asian, black, native american, indian, pacific islander, hispanic / latin                                  0.000018\n",
      "asian, middle eastern, hispanic / latin, white, other                                                      0.000018\n",
      "middle eastern, black, native american, indian                                                             0.000018\n",
      "black, native american, pacific islander, hispanic / latin                                                 0.000018\n",
      "native american, indian, white                                                                             0.000018\n",
      "asian, native american, hispanic / latin, other                                                            0.000018\n",
      "black, native american, indian                                                                             0.000018\n",
      "asian, middle eastern, indian, hispanic / latin                                                            0.000018\n",
      "asian, middle eastern, native american, pacific islander, other                                            0.000018\n",
      "indian, pacific islander, hispanic / latin, white                                                          0.000018\n",
      "asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin                  0.000018\n",
      "asian, middle eastern, native american, pacific islander, white, other                                     0.000018\n",
      "black, native american, indian, pacific islander                                                           0.000018\n",
      "middle eastern, black, other                                                                               0.000018\n",
      "asian, black, pacific islander, hispanic / latin, white                                                    0.000018\n",
      "asian, native american, indian, pacific islander, hispanic / latin, white, other                           0.000018\n",
      "asian, middle eastern, black, pacific islander, hispanic / latin                                           0.000018\n",
      "asian, black, pacific islander, white, other                                                               0.000018\n",
      "asian, black, indian                                                                                       0.000018\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# just so I can see everything\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(profiles['ethnicity'].value_counts(0).sum())\n",
    "print(profiles['ethnicity'].value_counts(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So yeah, a bunch of options and some NaN values. I'll fill those with 'unknown' and we'll one-hot encode the rest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 72 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   age                                 59946 non-null  int64  \n",
      " 1   drinks                              59946 non-null  int64  \n",
      " 2   drugs                               59946 non-null  int64  \n",
      " 3   essay0                              54458 non-null  object \n",
      " 4   essay1                              52374 non-null  object \n",
      " 5   essay2                              50308 non-null  object \n",
      " 6   essay3                              48470 non-null  object \n",
      " 7   essay4                              49409 non-null  object \n",
      " 8   essay5                              49096 non-null  object \n",
      " 9   essay6                              46175 non-null  object \n",
      " 10  essay7                              47495 non-null  object \n",
      " 11  essay8                              40721 non-null  object \n",
      " 12  essay9                              47343 non-null  object \n",
      " 13  height                              59943 non-null  float64\n",
      " 14  income                              59946 non-null  int64  \n",
      " 15  job                                 51748 non-null  object \n",
      " 16  last_online                         59946 non-null  object \n",
      " 17  location                            59946 non-null  object \n",
      " 18  offspring                           24385 non-null  object \n",
      " 19  orientation                         59946 non-null  object \n",
      " 20  pets                                40025 non-null  object \n",
      " 21  religion                            39720 non-null  object \n",
      " 22  sex                                 59946 non-null  object \n",
      " 23  sign                                48890 non-null  object \n",
      " 24  smokes                              54434 non-null  object \n",
      " 25  speaks                              59896 non-null  object \n",
      " 26  status                              59946 non-null  object \n",
      " 27  body_type_a little extra            59946 non-null  int64  \n",
      " 28  body_type_athletic                  59946 non-null  int64  \n",
      " 29  body_type_average                   59946 non-null  int64  \n",
      " 30  body_type_curvy                     59946 non-null  int64  \n",
      " 31  body_type_fit                       59946 non-null  int64  \n",
      " 32  body_type_full figured              59946 non-null  int64  \n",
      " 33  body_type_jacked                    59946 non-null  int64  \n",
      " 34  body_type_overweight                59946 non-null  int64  \n",
      " 35  body_type_rather not say            59946 non-null  int64  \n",
      " 36  body_type_skinny                    59946 non-null  int64  \n",
      " 37  body_type_thin                      59946 non-null  int64  \n",
      " 38  body_type_unknown                   59946 non-null  int64  \n",
      " 39  body_type_used up                   59946 non-null  int64  \n",
      " 40  diet_type_anything                  59946 non-null  int64  \n",
      " 41  diet_type_halal                     59946 non-null  int64  \n",
      " 42  diet_type_kosher                    59946 non-null  int64  \n",
      " 43  diet_type_other                     59946 non-null  int64  \n",
      " 44  diet_type_unknown                   59946 non-null  int64  \n",
      " 45  diet_type_vegan                     59946 non-null  int64  \n",
      " 46  diet_type_vegetarian                59946 non-null  int64  \n",
      " 47  diet_strictness                     59946 non-null  int64  \n",
      " 48  education_status_dropped_out        59946 non-null  int64  \n",
      " 49  education_status_graduated          59946 non-null  int64  \n",
      " 50  education_status_unknown            59946 non-null  int64  \n",
      " 51  education_status_unspecified        59946 non-null  int64  \n",
      " 52  education_status_working_on         59946 non-null  int64  \n",
      " 53  education_level_college/university  59946 non-null  int64  \n",
      " 54  education_level_high school         59946 non-null  int64  \n",
      " 55  education_level_law school          59946 non-null  int64  \n",
      " 56  education_level_masters program     59946 non-null  int64  \n",
      " 57  education_level_med school          59946 non-null  int64  \n",
      " 58  education_level_ph.d program        59946 non-null  int64  \n",
      " 59  education_level_space camp          59946 non-null  int64  \n",
      " 60  education_level_two-year college    59946 non-null  int64  \n",
      " 61  education_level_unknown             59946 non-null  int64  \n",
      " 62  ethinicity_white                    59946 non-null  int64  \n",
      " 63  ethinicity_asian                    59946 non-null  int64  \n",
      " 64  ethinicity_hispanic_latin           59946 non-null  int64  \n",
      " 65  ethinicity_black                    59946 non-null  int64  \n",
      " 66  ethinicity_other                    59946 non-null  int64  \n",
      " 67  ethinicity_indian                   59946 non-null  int64  \n",
      " 68  ethinicity_pacific_islander         59946 non-null  int64  \n",
      " 69  ethinicity_native_american          59946 non-null  int64  \n",
      " 70  ethinicity_middle_eastern           59946 non-null  int64  \n",
      " 71  ethinicity_unknown                  59946 non-null  int64  \n",
      "dtypes: float64(1), int64(49), object(22)\n",
      "memory usage: 32.9+ MB\n"
     ]
    }
   ],
   "source": [
    "profiles['ethnicity'] = profiles['ethnicity'].fillna('unknown')\n",
    "\n",
    "ethinicities = ['white', 'asian', 'hispanic / latin', 'black', 'other', 'indian', 'pacific islander', 'native american', 'middle eastern', 'unknown']\n",
    "\n",
    "for ethinicity in ethinicities:\n",
    "    col_name = 'ethinicity_' + ethinicity.replace(' / ', '_').replace(' ', '_')\n",
    "    profiles[col_name] = profiles['ethnicity'].str.contains(ethinicity).astype(int)\n",
    "    \n",
    "    \n",
    "profiles = profiles.drop('ethnicity', axis=1)\n",
    "\n",
    "profiles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                                                                                  22\n",
       "drinks                                                                                2\n",
       "drugs                                                                                 0\n",
       "essay0                                about me:<br />\\n<br />\\ni would love to think...\n",
       "essay1                                currently working as an international agent fo...\n",
       "essay2                                making people laugh.<br />\\nranting about a go...\n",
       "essay3                                the way i look. i am a six foot half asian, ha...\n",
       "essay4                                books:<br />\\nabsurdistan, the republic, of mi...\n",
       "essay5                                food.<br />\\nwater.<br />\\ncell phone.<br />\\n...\n",
       "essay6                                                      duality and humorous things\n",
       "essay7                                trying to find someone to hang out with. i am ...\n",
       "essay8                                i am new to california and looking for someone...\n",
       "essay9                                you want to be swept off your feet!<br />\\nyou...\n",
       "height                                                                             75.0\n",
       "income                                                                               -1\n",
       "job                                                                      transportation\n",
       "last_online                                                            2012-06-28-20-30\n",
       "location                                                south san francisco, california\n",
       "offspring                                  doesn&rsquo;t have kids, but might want them\n",
       "orientation                                                                    straight\n",
       "pets                                                          likes dogs and likes cats\n",
       "religion                                          agnosticism and very serious about it\n",
       "sex                                                                                   m\n",
       "sign                                                                             gemini\n",
       "smokes                                                                        sometimes\n",
       "speaks                                                                          english\n",
       "status                                                                           single\n",
       "body_type_a little extra                                                              1\n",
       "body_type_athletic                                                                    0\n",
       "body_type_average                                                                     0\n",
       "body_type_curvy                                                                       0\n",
       "body_type_fit                                                                         0\n",
       "body_type_full figured                                                                0\n",
       "body_type_jacked                                                                      0\n",
       "body_type_overweight                                                                  0\n",
       "body_type_rather not say                                                              0\n",
       "body_type_skinny                                                                      0\n",
       "body_type_thin                                                                        0\n",
       "body_type_unknown                                                                     0\n",
       "body_type_used up                                                                     0\n",
       "diet_type_anything                                                                    1\n",
       "diet_type_halal                                                                       0\n",
       "diet_type_kosher                                                                      0\n",
       "diet_type_other                                                                       0\n",
       "diet_type_unknown                                                                     0\n",
       "diet_type_vegan                                                                       0\n",
       "diet_type_vegetarian                                                                  0\n",
       "diet_strictness                                                                       0\n",
       "education_status_dropped_out                                                          0\n",
       "education_status_graduated                                                            0\n",
       "education_status_unknown                                                              0\n",
       "education_status_unspecified                                                          0\n",
       "education_status_working_on                                                           1\n",
       "education_level_college/university                                                    1\n",
       "education_level_high school                                                           0\n",
       "education_level_law school                                                            0\n",
       "education_level_masters program                                                       0\n",
       "education_level_med school                                                            0\n",
       "education_level_ph.d program                                                          0\n",
       "education_level_space camp                                                            0\n",
       "education_level_two-year college                                                      0\n",
       "education_level_unknown                                                               0\n",
       "ethinicity_white                                                                      1\n",
       "ethinicity_asian                                                                      1\n",
       "ethinicity_hispanic_latin                                                             0\n",
       "ethinicity_black                                                                      0\n",
       "ethinicity_other                                                                      0\n",
       "ethinicity_indian                                                                     0\n",
       "ethinicity_pacific_islander                                                           0\n",
       "ethinicity_native_american                                                            0\n",
       "ethinicity_middle_eastern                                                             0\n",
       "ethinicity_unknown                                                                    0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Height!\n",
    "\n",
    "It's a straigh number! Just filling NaN with the mean will suffice (there's actually very few missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['height'] = profiles['height'].fillna(profiles['height'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "income\n",
      "-1          48442\n",
      " 20000       2952\n",
      " 100000      1621\n",
      " 80000       1111\n",
      " 30000       1048\n",
      " 40000       1005\n",
      " 50000        975\n",
      " 60000        736\n",
      " 70000        707\n",
      " 150000       631\n",
      " 1000000      521\n",
      " 250000       149\n",
      " 500000        48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(profiles['income'].value_counts(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a LOT of -1's. Change that to 0's. \n",
    "\n",
    "But I think this wouldn't be a very nice column for training. We'll keep this in mind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['income'] = profiles['income'].replace(-1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jobs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job\n",
       "other                                7589\n",
       "student                              4882\n",
       "science / tech / engineering         4848\n",
       "computer / hardware / software       4709\n",
       "artistic / musical / writer          4439\n",
       "sales / marketing / biz dev          4391\n",
       "medicine / health                    3680\n",
       "education / academia                 3513\n",
       "executive / management               2373\n",
       "banking / financial / real estate    2266\n",
       "entertainment / media                2250\n",
       "law / legal services                 1381\n",
       "hospitality / travel                 1364\n",
       "construction / craftsmanship         1021\n",
       "clerical / administrative             805\n",
       "political / government                708\n",
       "rather not say                        436\n",
       "transportation                        366\n",
       "unemployed                            273\n",
       "retired                               250\n",
       "military                              204\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles['job'].value_counts(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another multi-label!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['job'] = profiles['job'].fillna('unknown')\n",
    "\n",
    "profiles = pd.get_dummies(profiles, columns=['job'], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 93 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   age                                    59946 non-null  int64  \n",
      " 1   drinks                                 59946 non-null  int64  \n",
      " 2   drugs                                  59946 non-null  int64  \n",
      " 3   essay0                                 54458 non-null  object \n",
      " 4   essay1                                 52374 non-null  object \n",
      " 5   essay2                                 50308 non-null  object \n",
      " 6   essay3                                 48470 non-null  object \n",
      " 7   essay4                                 49409 non-null  object \n",
      " 8   essay5                                 49096 non-null  object \n",
      " 9   essay6                                 46175 non-null  object \n",
      " 10  essay7                                 47495 non-null  object \n",
      " 11  essay8                                 40721 non-null  object \n",
      " 12  essay9                                 47343 non-null  object \n",
      " 13  height                                 59946 non-null  float64\n",
      " 14  income                                 59946 non-null  int64  \n",
      " 15  last_online                            59946 non-null  object \n",
      " 16  location                               59946 non-null  object \n",
      " 17  offspring                              24385 non-null  object \n",
      " 18  orientation                            59946 non-null  object \n",
      " 19  pets                                   40025 non-null  object \n",
      " 20  religion                               39720 non-null  object \n",
      " 21  sex                                    59946 non-null  object \n",
      " 22  sign                                   48890 non-null  object \n",
      " 23  smokes                                 54434 non-null  object \n",
      " 24  speaks                                 59896 non-null  object \n",
      " 25  status                                 59946 non-null  object \n",
      " 26  body_type_a little extra               59946 non-null  int64  \n",
      " 27  body_type_athletic                     59946 non-null  int64  \n",
      " 28  body_type_average                      59946 non-null  int64  \n",
      " 29  body_type_curvy                        59946 non-null  int64  \n",
      " 30  body_type_fit                          59946 non-null  int64  \n",
      " 31  body_type_full figured                 59946 non-null  int64  \n",
      " 32  body_type_jacked                       59946 non-null  int64  \n",
      " 33  body_type_overweight                   59946 non-null  int64  \n",
      " 34  body_type_rather not say               59946 non-null  int64  \n",
      " 35  body_type_skinny                       59946 non-null  int64  \n",
      " 36  body_type_thin                         59946 non-null  int64  \n",
      " 37  body_type_unknown                      59946 non-null  int64  \n",
      " 38  body_type_used up                      59946 non-null  int64  \n",
      " 39  diet_type_anything                     59946 non-null  int64  \n",
      " 40  diet_type_halal                        59946 non-null  int64  \n",
      " 41  diet_type_kosher                       59946 non-null  int64  \n",
      " 42  diet_type_other                        59946 non-null  int64  \n",
      " 43  diet_type_unknown                      59946 non-null  int64  \n",
      " 44  diet_type_vegan                        59946 non-null  int64  \n",
      " 45  diet_type_vegetarian                   59946 non-null  int64  \n",
      " 46  diet_strictness                        59946 non-null  int64  \n",
      " 47  education_status_dropped_out           59946 non-null  int64  \n",
      " 48  education_status_graduated             59946 non-null  int64  \n",
      " 49  education_status_unknown               59946 non-null  int64  \n",
      " 50  education_status_unspecified           59946 non-null  int64  \n",
      " 51  education_status_working_on            59946 non-null  int64  \n",
      " 52  education_level_college/university     59946 non-null  int64  \n",
      " 53  education_level_high school            59946 non-null  int64  \n",
      " 54  education_level_law school             59946 non-null  int64  \n",
      " 55  education_level_masters program        59946 non-null  int64  \n",
      " 56  education_level_med school             59946 non-null  int64  \n",
      " 57  education_level_ph.d program           59946 non-null  int64  \n",
      " 58  education_level_space camp             59946 non-null  int64  \n",
      " 59  education_level_two-year college       59946 non-null  int64  \n",
      " 60  education_level_unknown                59946 non-null  int64  \n",
      " 61  ethinicity_white                       59946 non-null  int64  \n",
      " 62  ethinicity_asian                       59946 non-null  int64  \n",
      " 63  ethinicity_hispanic_latin              59946 non-null  int64  \n",
      " 64  ethinicity_black                       59946 non-null  int64  \n",
      " 65  ethinicity_other                       59946 non-null  int64  \n",
      " 66  ethinicity_indian                      59946 non-null  int64  \n",
      " 67  ethinicity_pacific_islander            59946 non-null  int64  \n",
      " 68  ethinicity_native_american             59946 non-null  int64  \n",
      " 69  ethinicity_middle_eastern              59946 non-null  int64  \n",
      " 70  ethinicity_unknown                     59946 non-null  int64  \n",
      " 71  job_artistic / musical / writer        59946 non-null  int64  \n",
      " 72  job_banking / financial / real estate  59946 non-null  int64  \n",
      " 73  job_clerical / administrative          59946 non-null  int64  \n",
      " 74  job_computer / hardware / software     59946 non-null  int64  \n",
      " 75  job_construction / craftsmanship       59946 non-null  int64  \n",
      " 76  job_education / academia               59946 non-null  int64  \n",
      " 77  job_entertainment / media              59946 non-null  int64  \n",
      " 78  job_executive / management             59946 non-null  int64  \n",
      " 79  job_hospitality / travel               59946 non-null  int64  \n",
      " 80  job_law / legal services               59946 non-null  int64  \n",
      " 81  job_medicine / health                  59946 non-null  int64  \n",
      " 82  job_military                           59946 non-null  int64  \n",
      " 83  job_other                              59946 non-null  int64  \n",
      " 84  job_political / government             59946 non-null  int64  \n",
      " 85  job_rather not say                     59946 non-null  int64  \n",
      " 86  job_retired                            59946 non-null  int64  \n",
      " 87  job_sales / marketing / biz dev        59946 non-null  int64  \n",
      " 88  job_science / tech / engineering       59946 non-null  int64  \n",
      " 89  job_student                            59946 non-null  int64  \n",
      " 90  job_transportation                     59946 non-null  int64  \n",
      " 91  job_unemployed                         59946 non-null  int64  \n",
      " 92  job_unknown                            59946 non-null  int64  \n",
      "dtypes: float64(1), int64(71), object(21)\n",
      "memory usage: 42.5+ MB\n"
     ]
    }
   ],
   "source": [
    "profiles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orientation\n",
       "straight    51606\n",
       "gay          5573\n",
       "bisexual     2767\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles['orientation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
